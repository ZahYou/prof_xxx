{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca08d53e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "df = pd.read_csv(\"data/raw_partner_headlines.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31320eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grundlegende Informationen über das Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1845559 entries, 0 to 1845558\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   Unnamed: 0  int64 \n",
      " 1   headline    object\n",
      " 2   url         object\n",
      " 3   publisher   object\n",
      " 4   date        object\n",
      " 5   stock       object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 49.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Grundlegende Informationen über das Dataset\n",
    "print(\"Grundlegende Informationen über das Dataset:\")\n",
    "df_info = df.info()\n",
    "print(df_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f68336d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Erster Blick auf die Daten:\n",
      "   Unnamed: 0                                           headline  \\\n",
      "0           2  Agilent Technologies Announces Pricing of $5……...   \n",
      "1           3  Agilent (A) Gears Up for Q2 Earnings: What's i...   \n",
      "2           4  J.P. Morgan Asset Management Announces Liquida...   \n",
      "3           5  Pershing Square Capital Management, L.P. Buys ...   \n",
      "4           6  Agilent Awards Trilogy Sciences with a Golden ...   \n",
      "\n",
      "                                                 url  publisher  \\\n",
      "0  http://www.gurufocus.com/news/1153187/agilent-...  GuruFocus   \n",
      "1  http://www.zacks.com/stock/news/931205/agilent...      Zacks   \n",
      "2  http://www.gurufocus.com/news/1138923/jp-morga...  GuruFocus   \n",
      "3  http://www.gurufocus.com/news/1138704/pershing...  GuruFocus   \n",
      "4  http://www.gurufocus.com/news/1134012/agilent-...  GuruFocus   \n",
      "\n",
      "                  date stock  \n",
      "0  2020-06-01 00:00:00     A  \n",
      "1  2020-05-18 00:00:00     A  \n",
      "2  2020-05-15 00:00:00     A  \n",
      "3  2020-05-15 00:00:00     A  \n",
      "4  2020-05-12 00:00:00     A  \n"
     ]
    }
   ],
   "source": [
    "# Erster Blick auf die Daten\n",
    "print(\"\\nErster Blick auf die Daten:\")\n",
    "df_head = df.head()\n",
    "print(df_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07544add",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd1f976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['url'], inplace=True)\n",
    "df.drop(columns=['publisher'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a05eb5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistische Zusammenfassung:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youne\\AppData\\Local\\Temp\\ipykernel_2052\\706450308.py:3: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  df_describe = df.describe(include='all')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       headline                 date    stock  quarter\n",
      "count                   1845559              1845559  1845559  1845559\n",
      "unique                   806998                 3731     6552       43\n",
      "top     Midday Gainers / Losers  2015-11-19 00:00:00       KR   2019Q4\n",
      "freq                       4009                 3600     3314    98474\n",
      "first                       NaN  1969-12-31 00:00:00      NaN      NaN\n",
      "last                        NaN  2020-06-04 00:00:00      NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "# Statistische Zusammenfassung\n",
    "print(\"\\nStatistische Zusammenfassung:\")\n",
    "df_describe = df.describe(include='all')\n",
    "print(df_describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ffb6c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Überprüfung auf fehlende Werte:\n",
      "headline    0\n",
      "date        0\n",
      "stock       0\n",
      "quarter     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Überprüfung auf fehlende Werte\n",
    "print(\"\\nÜberprüfung auf fehlende Werte:\")\n",
    "df_missing_values = df.isnull().sum()\n",
    "print(df_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a58bcff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verteilung der Aktien:\n",
      "KR       3314\n",
      "GXC      3238\n",
      "PGJ      3082\n",
      "YINN     3027\n",
      "JPM      2873\n",
      "         ... \n",
      "ARCPP       1\n",
      "HGH         1\n",
      "GFNSL       1\n",
      "DIA         1\n",
      "JBK         1\n",
      "Name: stock, Length: 6552, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verteilung der Aktien\n",
    "print(\"\\nVerteilung der Aktien:\")\n",
    "df_stock_distribution = df['stock'].value_counts()\n",
    "print(df_stock_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20bb2650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verteilung der Daten über die Zeit:\n",
      "1969-12        1\n",
      "2010-02      367\n",
      "2010-03     1700\n",
      "2010-04     1505\n",
      "2010-05     1120\n",
      "           ...  \n",
      "2020-02    24532\n",
      "2020-03    16077\n",
      "2020-04    20566\n",
      "2020-05    18832\n",
      "2020-06     1193\n",
      "Freq: M, Name: date, Length: 126, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verteilung der Daten über die Zeit\n",
    "print(\"\\nVerteilung der Daten über die Zeit:\")\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df_date_distribution = df['date'].dt.to_period('M').value_counts().sort_index()\n",
    "print(df_date_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "484ed7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datentyp der 'date'-Spalte konvertieren\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Verteilung der Daten über die Quartale\n",
    "df['quarter'] = df['date'].dt.to_period('Q')\n",
    "df_quarter_distribution = df['quarter'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e674199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\youne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\youne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\youne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\youne\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sicherstellen, dass die benötigten NLTK-Resourcen heruntergeladen sind\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1b874f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Func zur Testbereinigung \n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text) # del von HTML-Tags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # del von Sonderzeichen\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de3a8852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Texttokenisierung, Entfernen von Stoppwörtern und Lemmatisierung\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenisierung\n",
    "    tokens = word_tokenize(text)\n",
    "    # Entfernen von Stoppwörtern\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    # Lemmatisierung\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Zusammenfügen der Tokens zu einem String\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
